{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c448d013",
   "metadata": {},
   "source": [
    "# Welcome to Homework II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9c466d",
   "metadata": {},
   "source": [
    "### Please read the instructions in both the instructions.pdf (on Moodle) and in this notebook very carefully!\n",
    "\n",
    "**The following instructions are binding**:\n",
    "\n",
    "* Other than ```pandas```, no further other library imports are allowed. Both third-party imports and builtin modules are not allowed.\n",
    "* Do not delete any of the ````%%writefile```` or ```%run``` statements.\n",
    "* The cells containing the function definitions and the ```%%writefile``` magic should not have any other code than the function definition and the pre-defined statements including ```%writefile``` and ```import pandas as pd```/```from typing import ...```.  Make sure that the cell defining the function is cleared of other code after implementing the function code.\n",
    "* Replace the `pass` placeholder with your own code.\n",
    "* Do **not** change any function names.\n",
    "* Do **not** modify or remove any existing line of code within each function, except that you may remove the `pass` placeholder.\n",
    "* Ensure each function receives the required input and returns the required output.\n",
    "* Answer the questions in order and and comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3451f0c5",
   "metadata": {},
   "source": [
    "## Student Number #1: _20240266_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebbb512",
   "metadata": {},
   "source": [
    "## Student Number #2: 20240660"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b94865",
   "metadata": {},
   "source": [
    "## Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "723907a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abd793f",
   "metadata": {},
   "source": [
    "# Part I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5164da8a",
   "metadata": {},
   "source": [
    "#### 1) Create the **`load_retail_data(filepath: str)`** function which loads the Online Retail file (onlineretail.csv) into a pandas DataFrame and returns it. Call this function and save the result into a DataFrame called **`df`**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "19b8052f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting load_retail_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile load_retail_data.py\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load retail data from a CSV file\n",
    "# Since we tried to read the CSV file initially with latin1 encoding and it failed\n",
    "# We decided that exception handling is necessary , especially because we are dealing with I/O operations\n",
    "def load_retail_data(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads a retail CSV dataset into a pandas DataFrame.\n",
    "    Handles missing file paths and encoding issues gracefully.\n",
    "    \"\"\"\n",
    "    encoding = ['utf-8', 'latin1']\n",
    "    try:\n",
    "        # The default is utf-8 (we kept this to show that we are handling encoding exceptions)\n",
    "        # It will get an error, the file is not utf-8 encoded\n",
    "        df = pd.read_csv(filepath, sep=',')\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {filepath}\")\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Encoding error while reading the file: {filepath}\")\n",
    "        print(f\"Used {encoding[0]} encoding, will try to read the file again with {encoding[1]} encoding.\")\n",
    "        try : \n",
    "            df = pd.read_csv(filepath, sep=',', encoding= encoding[1])\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "d5adcbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding error while reading the file: onlineretail.csv\n",
      "Used utf-8 encoding, will try to read the file again with latin1 encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>536365</td>\n",
       "      <td>84406B</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029G</td>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029E</td>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InvoiceNo StockCode                          Description  Quantity  \\\n",
       "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
       "1    536365     71053                  WHITE METAL LANTERN         6   \n",
       "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
       "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
       "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
       "\n",
       "      InvoiceDate  UnitPrice  CustomerID         Country  \n",
       "0  12/1/2010 8:26       2.55     17850.0  United Kingdom  \n",
       "1  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
       "2  12/1/2010 8:26       2.75     17850.0  United Kingdom  \n",
       "3  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
       "4  12/1/2010 8:26       3.39     17850.0  United Kingdom  "
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run load_retail_data.py\n",
    "\n",
    "df = load_retail_data(\"onlineretail.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab2032a",
   "metadata": {},
   "source": [
    "#### 2) Create the **`missing_values_cleaner`** function, which takes a Pandas DataFrame as input and **returns the same DataFrame after removing all rows that contain null values in the** **`CustomerID`** **or** **`Description`** **columns.** Ensure that only nulls in these two columns are dropped, without affecting rows that have null values in other columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "4e76bff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting missing_values_cleaner.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile missing_values_cleaner.py\n",
    "import pandas as pd\n",
    "\n",
    "# dropna pandas docs \n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html\n",
    "\n",
    "def missing_values_cleaner(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Create a copy of the Dataframe so it does not modify the original reference\n",
    "    df = df.copy()\n",
    "    # dropna() method drops the null values in the dataframe\n",
    "    # subset so that null values are found in these collums then we delete the rows\n",
    "    # axis = index to delete the rows, the default is also rows deletion, but we want to show mastery of pandas usage\n",
    "    df = df.dropna(subset=['CustomerID', 'Description'], axis='index')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb67235d",
   "metadata": {},
   "source": [
    "#### Call your `missing_values_cleaner` function on the original `df` below to view the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "cd5acfe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>536365</td>\n",
       "      <td>84406B</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029G</td>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029E</td>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InvoiceNo StockCode                          Description  Quantity  \\\n",
       "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
       "1    536365     71053                  WHITE METAL LANTERN         6   \n",
       "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
       "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
       "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
       "\n",
       "      InvoiceDate  UnitPrice  CustomerID         Country  \n",
       "0  12/1/2010 8:26       2.55     17850.0  United Kingdom  \n",
       "1  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
       "2  12/1/2010 8:26       2.75     17850.0  United Kingdom  \n",
       "3  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
       "4  12/1/2010 8:26       3.39     17850.0  United Kingdom  "
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run missing_values_cleaner.py\n",
    "# Here the correct arguments should be added\n",
    "missing_values_cleaner(df).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "2cd72213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning: \n",
      "\n",
      "InvoiceNo           0\n",
      "StockCode           0\n",
      "Description      1454\n",
      "Quantity            0\n",
      "InvoiceDate         0\n",
      "UnitPrice           0\n",
      "CustomerID     135080\n",
      "Country             0\n",
      "dtype: int64\n",
      "\n",
      "After cleaning: \n",
      "\n",
      "InvoiceNo      0\n",
      "StockCode      0\n",
      "Description    0\n",
      "Quantity       0\n",
      "InvoiceDate    0\n",
      "UnitPrice      0\n",
      "CustomerID     0\n",
      "Country        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# To check for the null values we can use the DataFrame .isna() \n",
    "# .isna() docs https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isna.html#pandas.DataFrame.isna\n",
    "\n",
    "# Here we can see the number of missing values before and after cleaning\n",
    "# In this case we can use .sum to check how many null values exist\n",
    "# This works because the True and False mapped by isna() are treated like 1 or 0 like C, so sum() just sums it up\n",
    "\n",
    "print(\"Before cleaning: \\n\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "print(\"\\nAfter cleaning: \\n\")\n",
    "print(missing_values_cleaner(df).isna().sum())\n",
    "\n",
    "\n",
    "# Unit testing\n",
    "\n",
    "# before testing can we find any missing values? \n",
    "assert df['Description'].isna().any()\n",
    "assert df['CustomerID'].isna().any()\n",
    "\n",
    "# after testing we should not find any missing values\n",
    "\n",
    "cleaned_df = missing_values_cleaner(df)\n",
    "assert not cleaned_df['Description'].isna().any()\n",
    "assert not cleaned_df['CustomerID'].isna().any()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2e73cb",
   "metadata": {},
   "source": [
    "#### 3) Create the **`quantity_handler`** function, which takes a Pandas DataFrame as input and **returns the same DataFrame after removing all rows that contain negative or 0 values in the** **`Quantity`** **column.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "75a04a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting quantity_handler.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile quantity_handler.py\n",
    "import pandas as pd\n",
    "\n",
    "# For this exercise we want to filter the rows that have 'Quantity > 0'\n",
    "# We can use boolean logic such as df[df['Quantity'] > 0]\n",
    "# We choosed to use query SQL WHERE conditional logic, df.query('Quantity > 0')\n",
    "# Docs for DataFrame.query:\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html\n",
    "\n",
    "def quantity_handler(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Create a copy of the Dataframe so it does not modify the original reference\n",
    "    df = df.copy()\n",
    "    return df.query('Quantity > 0')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86278ffc",
   "metadata": {},
   "source": [
    "#### Call your `quantity_handler` function on the original `df` below to view the results:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "be221de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>536365</td>\n",
       "      <td>84406B</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029G</td>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029E</td>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InvoiceNo StockCode                          Description  Quantity  \\\n",
       "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
       "1    536365     71053                  WHITE METAL LANTERN         6   \n",
       "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
       "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
       "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
       "\n",
       "      InvoiceDate  UnitPrice  CustomerID         Country  \n",
       "0  12/1/2010 8:26       2.55     17850.0  United Kingdom  \n",
       "1  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
       "2  12/1/2010 8:26       2.75     17850.0  United Kingdom  \n",
       "3  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
       "4  12/1/2010 8:26       3.39     17850.0  United Kingdom  "
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run quantity_handler.py\n",
    "\n",
    "# Here the correct arguments should be added\n",
    "quantity_handler(df).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "937a3703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before quantity handling: \n",
      "-80995\n",
      "After quantity handling:\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(\"Before quantity handling: \")\n",
    "print(df['Quantity'].min())\n",
    "\n",
    "print(\"After quantity handling:\")\n",
    "print(quantity_handler(df)['Quantity'].min())\n",
    "\n",
    "# Unit Testing\n",
    "\n",
    "# Before it had some negative or zero values\n",
    "assert (df['Quantity'] < 0).any()\n",
    "assert df['Quantity'].min() <= 0\n",
    "\n",
    "# After it should not , also min value should be over 0\n",
    "assert not (quantity_handler(df)['Quantity'] < 0).any()\n",
    "assert quantity_handler(df)['Quantity'].min() > 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27a605a",
   "metadata": {},
   "source": [
    "#### 4) Create the **`amount_spent_computer`** function, which takes a Pandas DataFrame as input and **returns the same DataFrame with an added column named** **`amount_spent`**. This column should represent the product of **`Quantity`** and **`UnitPrice`**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "dd07698b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting amount_spent_computer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile amount_spent_computer.py\n",
    "import pandas as pd\n",
    "\n",
    "def amount_spent_computer(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Create a copy of the Dataframe so it does not modify the original reference\n",
    "    df = df.copy()\n",
    "    # We add a new column called 'amount_spent' df['amount_spent'] \n",
    "    # Since we are going to multiply and save the result in the 'amount_spent' column\n",
    "    # We need to treat missing values , by replacing them with 0 to avoid errors\n",
    "    df['Quantity'] = pd.to_numeric(df['Quantity'], errors='coerce').fillna(0)\n",
    "    df['UnitPrice'] = pd.to_numeric(df['UnitPrice'], errors='coerce').fillna(0)\n",
    "    df['amount_spent'] = df['Quantity'] * df['UnitPrice']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b30a629",
   "metadata": {},
   "source": [
    "#### Call your `amount_spent_computer` function on the original `df` below to view the results:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "867711ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run amount_spent_computer.py\n",
    "\n",
    "# PRINTING WITH THE ORIGINAL DATAFRAME\n",
    "amount_spent_computer(df).head()\n",
    "\n",
    "# Unit tests for amount_spent_computer(df: pd.DataFrame) (WE USE TESTING DATAFRAMES)\n",
    "\n",
    "# Sample DataFrame\n",
    "# Notice we considered combination of null/na values in both columns\n",
    "df_test = pd.DataFrame({\n",
    "    'Quantity': [1, 2, 3, None],\n",
    "    'UnitPrice': [10, 20, None, 5]\n",
    "})\n",
    "\n",
    "# Compute result\n",
    "result_df = amount_spent_computer(df_test)\n",
    "\n",
    "# check if there is a line which 'amount_spent' value does not match the multiplication of the 'Quantity' column times 'UnitPrice'\n",
    "assert not (result_df['amount_spent'] != result_df['Quantity'] * result_df['UnitPrice']).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec758ee",
   "metadata": {},
   "source": [
    "#### 5) Create the **`date_handler`** function, which takes a Pandas DataFrame as input and **returns the same DataFrame without any invoices from the year 2011.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "ea261964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting date_handler.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile date_handler.py\n",
    "import pandas as pd\n",
    "\n",
    "# pandas to_datetime() docs : https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html\n",
    "\n",
    "def date_handler(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Create a copy of the Dataframe so it does not modify the original reference\n",
    "    df = df.copy()\n",
    "    # We will convert this column to datetime type, so we can use dt.year, dt.month, dt.day, etc.\n",
    "    # For the arg passed in the to_datetime() method we pass a 1d Series that is the collumn 'InvoiceDate' of the DataFrame\n",
    "    df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "    return df.query(\"InvoiceDate.dt.year != 2011\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571ab24f",
   "metadata": {},
   "source": [
    "#### Call your `date_handler` function on the original `df` below to view the results:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "f0b3c7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Invoice handling: \n",
      "[2010 2011]\n",
      "After Invoice handling:\n",
      "[2010]\n"
     ]
    }
   ],
   "source": [
    "%run date_handler.py\n",
    "# Here the correct arguments should be added\n",
    "df_time_test = df.copy()\n",
    "df_time_test['InvoiceDate'] = pd.to_datetime(df_time_test['InvoiceDate'])\n",
    "print(\"Before Invoice handling: \")\n",
    "print(df_time_test['InvoiceDate'].dt.year.unique())\n",
    "print(\"After Invoice handling:\")\n",
    "print(date_handler(df)['InvoiceDate'].dt.year.unique())\n",
    "\n",
    "# Unit Testing\n",
    "\n",
    "df_test = pd.DataFrame({\n",
    "    'InvoiceDate': ['2010-12-31', '2011-01-01', '2012-06-15']\n",
    "})  \n",
    "\n",
    "# Before testing we have 1 row with year 2011\n",
    "assert (pd.to_datetime(df_test['InvoiceDate'], errors='coerce').dt.year == 2011).sum() == 1\n",
    "\n",
    "\n",
    "# After testing we should not have any row with year 2011\n",
    "cleaned_df = date_handler(df_test)\n",
    "assert not (cleaned_df['InvoiceDate'].dt.year == 2011).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b944cbc",
   "metadata": {},
   "source": [
    "#### 6) Create the **`data_cleaner`** function, which takes a Pandas DataFrame as input and **returns the same DataFrame after cleaning.** The cleaning process must follow the instructions provided inside the function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "710136e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data_cleaner.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_cleaner.py\n",
    "import pandas as pd\n",
    "from missing_values_cleaner import missing_values_cleaner\n",
    "from quantity_handler import quantity_handler\n",
    "from amount_spent_computer import amount_spent_computer\n",
    "from date_handler import date_handler\n",
    "\n",
    "def data_cleaner(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    This function receives a Pandas DataFrame as input.\n",
    "\n",
    "    First, pass the input DataFrame `df` to the `missing_values_cleaner`\n",
    "    function, and store its output in a new variable called `clean`.\n",
    "    Then, pass `clean` to the `quantity_handler` function and store its\n",
    "    output (you may reuse the variable name `clean`).\n",
    "\n",
    "    Next, pass the resulting DataFrame to the `amount_spent_computer`\n",
    "    function, and then to the `date_handler` function. Finally, return\n",
    "    the fully cleaned DataFrame.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Even though 'returns the same DataFrame after cleaning' we choosed to make a deep copy of the dataframe\n",
    "    # Create a copy of the Dataframe so it does not modify the original reference\n",
    "    df = df.copy()\n",
    "    clean = quantity_handler(missing_values_cleaner(df))\n",
    "    amount_spent_clean = amount_spent_computer(clean)\n",
    "    fully_clean = date_handler(amount_spent_clean)\n",
    "    return fully_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eca1410",
   "metadata": {},
   "source": [
    "#### Now, before we proceed. We will clean our data using your **`data_cleaner`** function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "2431fb43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "      <th>amount_spent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>15.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>20.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>536365</td>\n",
       "      <td>84406B</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029G</td>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>20.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029E</td>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>20.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InvoiceNo StockCode                          Description  Quantity  \\\n",
       "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
       "1    536365     71053                  WHITE METAL LANTERN         6   \n",
       "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
       "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
       "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
       "\n",
       "          InvoiceDate  UnitPrice  CustomerID         Country  amount_spent  \n",
       "0 2010-12-01 08:26:00       2.55     17850.0  United Kingdom         15.30  \n",
       "1 2010-12-01 08:26:00       3.39     17850.0  United Kingdom         20.34  \n",
       "2 2010-12-01 08:26:00       2.75     17850.0  United Kingdom         22.00  \n",
       "3 2010-12-01 08:26:00       3.39     17850.0  United Kingdom         20.34  \n",
       "4 2010-12-01 08:26:00       3.39     17850.0  United Kingdom         20.34  "
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run data_cleaner.py\n",
    "# Here the correct arguments should be added\n",
    "#perguntar professor, limpar todos os datasets\n",
    "df = data_cleaner(df)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf048f9e",
   "metadata": {},
   "source": [
    "#### 7) Create the **`top_five_cust`** function, which takes a Pandas DataFrame as input and **returns a list of** **`CustomerID`s** **corresponding to the five customers who have placed the highest number of orders.** Note that the same invoice number (`InvoiceNo`) represents a single order, even if it appears across multiple rows! Be careful with these repetitions ;)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "1781347d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting top_five_cust.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile top_five_cust.py\n",
    "import pandas as pd\n",
    "\n",
    "# To solve this exercise we want to find the top 5 customers by number of unique orders\n",
    "# We can use groupby() method to group by CustomerID and then use nunique()\n",
    "# groupby() docs: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html\n",
    "# nunique() docs: https://pandas.pydata.org/docs/reference/api/pandas.Series.nunique.html\n",
    "\n",
    "\n",
    "def top_five_cust(df: pd.DataFrame) -> list:\n",
    "    # Create a copy of the Dataframe so it does not modify the original reference\n",
    "    df = df.copy()\n",
    "\n",
    "    # Remove the na CustomerID values\n",
    "    df = df.dropna(subset=['CustomerID'], axis='index')\n",
    "\n",
    "    # Number of unique orders per CustomerID\n",
    "    order_counts = df.groupby('CustomerID')['InvoiceNo'].nunique()\n",
    "\n",
    "    # Sort descending and take top 5\n",
    "    top_customers = order_counts.sort_values(ascending=False).head(5)\n",
    "\n",
    "    # Return CustomerIDs as a list\n",
    "    return top_customers.index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c3120e",
   "metadata": {},
   "source": [
    "#### Call your `top_five_cust` function on the now cleaned `df` below to view the results:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "da9f3679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12748.0, 17850.0, 14911.0, 15061.0, 13777.0]\n"
     ]
    }
   ],
   "source": [
    "%run top_five_cust.py\n",
    "# Here the correct arguments should be added\n",
    "#top_five_cust(df)\n",
    "print(top_five_cust(df))\n",
    "\n",
    "# Unit Testing\n",
    "# Sample DataFrame size 10 rows\n",
    "\n",
    "df_test = pd.DataFrame({\n",
    "    'CustomerID': [1, 2, 1, 3, 2, 4, 5, 1, 2, None],\n",
    "    'InvoiceNo': [101, 102, 103, 104, 105, 106, 107, 108, 109, 110]\n",
    "})\n",
    "\n",
    "# Compute top five customers\n",
    "top_customers = top_five_cust(df_test)\n",
    "\n",
    "# Check if the length of the result list is 5 or less (in case there are less than 5 unique customers)\n",
    "assert len(top_customers) <= 5\n",
    "\n",
    "# Check if the top customer is indeed the one with the most unique orders\n",
    "# CustomerID 1 has 3 unique orders (101, 103, 108)\n",
    "assert top_customers[0] == 1\n",
    "# CustomerID 2 has 3 unique orders (102, 105, 109)\n",
    "assert top_customers[1] == 2\n",
    "# CustomerID 3 has 1 unique order (104)\n",
    "assert top_customers[2] == 3\n",
    "# CustomerID 4 has 1 unique order (106)\n",
    "assert top_customers[3] == 4\n",
    "# CustomerID 5 has 1 unique order (107)\n",
    "assert top_customers[4] == 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7b31c9",
   "metadata": {},
   "source": [
    "#### 8) Create the **`top_five_spenders`** function, which takes a Pandas DataFrame as input and **returns a list of** **`CustomerID`s** **corresponding to the five customers who have spent the most money.** Use the newly created **`amount_spent`** column for this exercise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "4ff3eb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting top_five_spenders.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile top_five_spenders.py\n",
    "import pandas as pd\n",
    "from amount_spent_computer import amount_spent_computer\n",
    "\n",
    "def top_five_spenders(df: pd.DataFrame) -> list:\n",
    "    # Create a copy of the Dataframe so it does not modify the original reference\n",
    "    df = df.copy()\n",
    "\n",
    "    # Remove na CustomerID values\n",
    "    df_clean = df.dropna(subset=['CustomerID'], axis='index')\n",
    "\n",
    "    # Use previously defined amount_spent_computer function\n",
    "    # After this we will have a new column 'amount_spent' in the dataframe\n",
    "    df_with_amount_spent = amount_spent_computer(df_clean)\n",
    "\n",
    "    # For customerID we get all amount_spent and sum it up\n",
    "    total_spent = df_with_amount_spent.groupby('CustomerID')['amount_spent'].sum()\n",
    "\n",
    "    # Sort descending and take top 5\n",
    "    top_spenders = total_spent.sort_values(ascending=False).head(5)\n",
    "\n",
    "    # Return CustomerIDs as a list\n",
    "    return top_spenders.index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15009f25",
   "metadata": {},
   "source": [
    "#### Call your `top_five_spenders` function on the now cleaned `df` below to view the results:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "1b855ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run top_five_spenders.py\n",
    "# Here the correct arguments should be added\n",
    "top_five_spenders(df)\n",
    "\n",
    "# Unit Testing\n",
    "# Sample DataFrame size 10 rows\n",
    "\n",
    "df_test = pd.DataFrame({\n",
    "    'CustomerID': [1, 2, 1, 3, 2, 4, 5, 1, 2, None],\n",
    "    'Quantity': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'UnitPrice': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "})  \n",
    "\n",
    "# Compute top five spenders\n",
    "top_spenders = top_five_spenders(df_test)\n",
    "# Check if the length of the result list is 5 or less (in case there are less than 5 unique customers)\n",
    "assert len(top_spenders) <= 5\n",
    "# Check if the top spender is indeed the one with the highest total amount spent\n",
    "# CustomerID 1 spent: (1*10) + (3*30) + (8*80) = 740 \n",
    "# CustomerID 2 spent: (2*20) + (5*50) + (9*90) = 1100\n",
    "# CustomerID 3 spent: (4*40) = 160\n",
    "# CustomerID 4 spent: (6*60) = 360\n",
    "# CustomerID 5 spent: (7*70) = 490\n",
    "# Therefore, the expected order is: [2, 1, 5, 4, 3]\n",
    "assert top_spenders[0] == 2\n",
    "assert top_spenders[1] == 1\n",
    "assert top_spenders[2] == 5\n",
    "assert top_spenders[3] == 4\n",
    "assert top_spenders[4] == 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81652ff",
   "metadata": {},
   "source": [
    "#### 9) Create the **`most_expensive_item`** function, which receives a Pandas DataFrame as input and **returns a string representing the `Description` of the most expensive item.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "2c9536b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting most_expensive_item.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile most_expensive_item.py\n",
    "import pandas as pd\n",
    "\n",
    "# To find the most expensive item we can use the max() method on the 'UnitPrice' collumn\n",
    "# Then we filter the dataframe to get the row with that max price and get the 'Description\n",
    "# Docs for max() method:\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.Series.max.html\n",
    "# Docs for iloc:\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html\n",
    "def most_expensive_item(df: pd.DataFrame) -> str:\n",
    "     # Create a copy of the Dataframe so it does not modify the original reference\n",
    "     df = df.copy()\n",
    "     # We get the max price in the 'UnitPrice' collumn\n",
    "     max_price = df['UnitPrice'].max()\n",
    "     # We filter the dataframe to get the rows with the max price\n",
    "     # We then get a Series with the 'Description' of the max price items\n",
    "     # Since there could be multiple items with the same max price we use iloc[0] to get the first one\n",
    "     most_expensive = df[df['UnitPrice'] == max_price]['Description'].iloc[0]\n",
    "     return most_expensive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ae896e",
   "metadata": {},
   "source": [
    "#### Call your `most_expensive_item` function on the now cleaned `df` below to view the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "a7a3234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run most_expensive_item.py\n",
    "# Here the correct arguments should be added\n",
    "most_expensive_item(df)\n",
    "\n",
    "# Unit Testing\n",
    "# Sample DataFrame\n",
    "df_test = pd.DataFrame({\n",
    "    'Description': ['Item A', 'Item B', 'Item C'],\n",
    "    'UnitPrice': [10.0, 20.0, 30.0]\n",
    "})\n",
    "\n",
    "# Compute most expensive item\n",
    "most_expensive = most_expensive_item(df_test)\n",
    "# Check if the most expensive item is correct (should be 'Item C')\n",
    "assert most_expensive == 'Item C'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebf4929",
   "metadata": {},
   "source": [
    "#### 10) Create the **`top_twenty_countries`** function, which receives a Pandas DataFrame as input and **returns a list of strings containing the 20 countries with the highest number of orders.** Note that this follows the same logic as question 7, so be careful with repeated orders (same invoice numbers)!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "8ed75b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting top_twenty_countries.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile top_twenty_countries.py\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "\n",
    "# To find the top twenty countries by number of unique orders\n",
    "# First we can do a prevention check to delete any na values in the 'Country' column\n",
    "# We can use groupby() method to group by Country and then use nunique()\n",
    "# groupby() docs: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html\n",
    "# nunique() docs: https://pandas.pydata.org/docs/reference/api/pandas.Series.nunique.html\n",
    "def top_twenty_countries(df: pd.DataFrame) -> List[str]:\n",
    "    # Create a copy of the Dataframe so it does not modify the original reference\n",
    "    df = df.copy()\n",
    "\n",
    "    # Remove na Country values\n",
    "    clean_df = df.dropna(subset=['Country'], axis='index')\n",
    "\n",
    "    # Number of unique orders per Country\n",
    "    order_per_country = clean_df.groupby('Country')['InvoiceNo'].nunique()\n",
    "\n",
    "    # Sort descending and take top 20 (we will get the highest 20 countries by number of unique orders)\n",
    "    top_twenty_countries = order_per_country.sort_values(ascending=False).head(20)\n",
    "    \n",
    "    # Return Country names as a list (since we groupedBy Country the index will be the Country names)\n",
    "    return top_twenty_countries.index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925b8871",
   "metadata": {},
   "source": [
    "#### Call your `top_twenty_countries` function on the now cleaned `df` below to view the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "38fae386",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run top_twenty_countries.py\n",
    "# Here the correct arguments should be added\n",
    "top_twenty_countries(df)\n",
    "\n",
    "# Unit Testing\n",
    "# Sample DataFrame size 26 rows\n",
    "df_test = pd.DataFrame({\n",
    "    'Country': ['A', 'B', 'A', 'C', 'B', 'D', 'E', 'A', 'B', 'C',\n",
    "                'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
    "                'N', 'O', 'P', 'Q', 'R', None],\n",
    "    'InvoiceNo': [101, 102, 103, 104, 105, 106, 107, 108, 109, 110,\n",
    "                    111, 112, 113, 114, 115, 116,\n",
    "                    117, 118, 119, 120,\n",
    "                    121, 122, 123, 124, 125, 126]\n",
    "})\n",
    "\n",
    "# Compute top twenty countries\n",
    "top_countries = top_twenty_countries(df_test)\n",
    "# Check if the length of the result list is 20 or less (in case there are less than 20 unique countries)\n",
    "assert len(top_countries) <= 20\n",
    "# Check if the top country is indeed the one with the most unique orders\n",
    "# Country A has 3 unique orders (101, 103, 108)\n",
    "assert top_countries[0] == 'A'\n",
    "# Country B has 3 unique orders (102, 105, 109)\n",
    "assert top_countries[1] == 'B'\n",
    "# Country C has 2 unique orders (104, 110)\n",
    "assert top_countries[2] == 'C'\n",
    "# Country D has 2 unique orders (106, 111)\n",
    "assert top_countries[3] == 'D'\n",
    "# Country E has 2 unique orders (107, 112)\n",
    "assert top_countries[4] == 'E'\n",
    "# The rest of the countries have 1 unique order each , so they should be next\n",
    "assert set(top_countries[5:]) == set(['F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R'])     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b18f1b",
   "metadata": {},
   "source": [
    "#### 11) Create the **`popular_products`** function, which receives a Pandas DataFrame as input and **returns a list of strings representing the descriptions (`Description`) of the 5 products purchased the most times.** Note that “number of times” refers only to how often an item was purchased, not the quantity of each order!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "0d1fd529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting popular_products.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile popular_products.py\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "# We will have to find the top 5 most popular products by number of unique orders\n",
    "# We can use groupby() method to group by Description and then use nunique()\n",
    "# This means that we will get every description per unique InvoiceNo\n",
    "# So we are essentially counting how many unique InvoiceNos each Description appears in\n",
    "# So essentially how many times each product was ordered\n",
    "def popular_products(df: pd.DataFrame) -> List[str]:\n",
    "    # Create a copy of the Dataframe so it does not modify the original reference\n",
    "    df = df.copy()\n",
    "    # First lets drop any rows with missing values in the 'Description' column (to avoid possible errors)\n",
    "    df = df.dropna(subset=['Description'], axis='index')\n",
    "    # Check number of times every product was ordered (in distinct Invoices)\n",
    "    top_products = df.groupby('Description')['InvoiceNo'].nunique().sort_values(ascending=False).head(5)\n",
    "    # Het the product descriptions as a list\n",
    "    top_products_list = top_products.index.tolist()\n",
    "    return top_products_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eb3735",
   "metadata": {},
   "source": [
    "#### Call your `popular_products` function on the now cleaned `df` below to view the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "236f1662",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run popular_products.py\n",
    "# Here the correct arguments should be added\n",
    "popular_products(df)\n",
    "\n",
    "# Unit Testing\n",
    "# Sample DataFrame size 10 rows\n",
    "df_test = pd.DataFrame({\n",
    "    'Description': ['Product A', 'Product B', 'Product A', 'Product C ', 'Product B',\n",
    "                    'Product D', 'Product E', 'Product A', 'Product B', 'Product F'],\n",
    "    'InvoiceNo': [101, 102, 103, 104, 105, 106, 107, 108, 109, 110]\n",
    "})\n",
    "\n",
    "# Compute popular products\n",
    "popular_prods = popular_products(df_test)\n",
    "# Check if the length of the result list is 5 or less (in case there are\n",
    "assert len(popular_prods) <= 5\n",
    "# Check if the top product is indeed the one with the most unique orders\n",
    "# Product A has 3 unique orders (101, 103, 108)\n",
    "assert popular_prods[0] == 'Product A'\n",
    "# Product B has 3 unique orders (102, 105, 109)\n",
    "assert popular_prods[1] == 'Product B'\n",
    "# Product C has 1 unique order (104)\n",
    "assert popular_prods[2] == 'Product C '\n",
    "# Product D has 1 unique order (106)\n",
    "assert popular_prods[3] == 'Product D'\n",
    "# Product E has 1 unique order (107)\n",
    "assert popular_prods[4] == 'Product E'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89e71a1",
   "metadata": {},
   "source": [
    "#### 12) Create the **`country_best_product`** function, which receives a Pandas DataFrame and a string as input. The string represents a country. The function must **return** `None` if the country is not present in the DataFrame. Otherwise, it should **return the description of the item that is most frequently purchased in that country.** Remember that “most frequently purchased” refers to how often the item appears, not the quantity purchased.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb9c986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting country_best_product.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile country_best_product.py\n",
    "import pandas as pd\n",
    "\n",
    "def country_best_product(df: pd.DataFrame, country: str) -> str:\n",
    "    # Create a copy of the Dataframe so it does not modify the original reference\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Remove na Country values\n",
    "    clean_df = df.dropna(subset=['Country'], axis='index')\n",
    "\n",
    "    # Filter to only get dataframe rows that are equal to the country\n",
    "    country_df = df[df['Country'] == country]\n",
    "    \n",
    "    if country_df.empty:\n",
    "        return None\n",
    "\n",
    "    # Get counting of product descriptions per country    \n",
    "    # sort_values(ascending=False) to sort by most ordered\n",
    "    product_sales = country_df.groupby('Country')['Description'].value_counts().sort_values(ascending=False)\n",
    "\n",
    "    # Get head(1) to get the most ordered product order per country\n",
    "    best_product = product_sales.head(1)\n",
    "    return best_product.index[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a1ee9c",
   "metadata": {},
   "source": [
    "#### Call your `country_best_product` function on the now cleaned `df` and \"Portugal\" below to view the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "8a036edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSTAGE\n"
     ]
    }
   ],
   "source": [
    "%run country_best_product.py\n",
    "# Here the correct arguments should be added\n",
    "print(country_best_product(df,\"Portugal\"))\n",
    "\n",
    "# Unit test \n",
    "\n",
    "# Create a simple DataFrame\n",
    "df_test = pd.DataFrame({\n",
    "    'Country': ['United Kingdom', 'United Kingdom', 'United Kingdom',\n",
    "                'France', 'France', None],\n",
    "    'Description': ['Apple', 'Banana', 'Apple', 'Banana', 'Orange', 'Apple']\n",
    "})\n",
    "\n",
    "# --- Test 1: UK has 'Apple' most often ---\n",
    "best_uk = country_best_product(df_test, 'United Kingdom')\n",
    "assert best_uk == 'Apple', f\"Expected 'Apple' but got {best_uk}\"\n",
    "\n",
    "# --- Test 2: France has 'Banana' most often ---\n",
    "best_fr = country_best_product(df_test, 'France')\n",
    "assert best_fr == 'Banana', f\"Expected 'Banana' but got {best_fr}\"\n",
    "\n",
    "# --- Test 3: Missing or invalid country returns None ---\n",
    "best_none = country_best_product(df_test, 'Germany')\n",
    "assert best_none is None, f\"Expected None but got {best_none}\"\n",
    "\n",
    "# --- Test 4: NaN country rows are ignored ---\n",
    "df_with_nan = pd.DataFrame({\n",
    "    'Country': [None, 'France', 'France'],\n",
    "    'Description': ['Apple', 'Orange', 'Orange']\n",
    "})\n",
    "best_fr_nan = country_best_product(df_with_nan, 'France')\n",
    "assert best_fr_nan == 'Orange', f\"Expected 'Orange' but got {best_fr_nan}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c49ba76",
   "metadata": {},
   "source": [
    "# Part II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf36734",
   "metadata": {},
   "source": [
    "#### 13) Create the **`load_customer_data(filepath: str)`** function which loads the **`customer_info.csv`** file into a Pandas DataFrame and returns it. Call this function and save the result into a DataFrame named **`customers`**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "4094ee1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting load_customer_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile load_customer_data.py\n",
    "import pandas as pd\n",
    "\n",
    "def load_customer_data(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads a customer CSV dataset into a pandas DataFrame.\n",
    "    Handles missing file paths and encoding issues gracefully.\n",
    "    \"\"\"\n",
    "    encoding = ['utf-8', 'latin1']\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, sep=',')\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {filepath}\")\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Encoding error while reading the file: {filepath}\")\n",
    "        print(f\"Used {encoding[0]} encoding, will try to read the file again with {encoding[1]} encoding.\")\n",
    "        try : \n",
    "            df = pd.read_csv(filepath, sep=',', encoding= encoding[1])\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "6b71d07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>Email</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Age</th>\n",
       "      <th>YearsActive</th>\n",
       "      <th>NumChildren</th>\n",
       "      <th>VIP</th>\n",
       "      <th>EstimatedAnnualSpend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17850.0</td>\n",
       "      <td>Rowan</td>\n",
       "      <td>White</td>\n",
       "      <td>rowan.white0.0@mail.test</td>\n",
       "      <td>+6-642-419-1833</td>\n",
       "      <td>56</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>5352.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13047.0</td>\n",
       "      <td>Casey</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>casey.johnson7.0@sample.net</td>\n",
       "      <td>+5-208-357-5102</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>1554.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12583.0</td>\n",
       "      <td>Morgan</td>\n",
       "      <td>Harris</td>\n",
       "      <td>morgan.harris3.0@sample.net</td>\n",
       "      <td>+1-877-772-1298</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>3396.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13748.0</td>\n",
       "      <td>Casey</td>\n",
       "      <td>Harris</td>\n",
       "      <td>casey.harris8.0@demo.org</td>\n",
       "      <td>+5-854-311-7228</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>1243.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15100.0</td>\n",
       "      <td>Riley</td>\n",
       "      <td>Thompson</td>\n",
       "      <td>riley.thompson0.0@mail.test</td>\n",
       "      <td>+2-818-901-1646</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>661.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID FirstName  LastName                        Email  \\\n",
       "0     17850.0     Rowan     White     rowan.white0.0@mail.test   \n",
       "1     13047.0     Casey   Johnson  casey.johnson7.0@sample.net   \n",
       "2     12583.0    Morgan    Harris  morgan.harris3.0@sample.net   \n",
       "3     13748.0     Casey    Harris     casey.harris8.0@demo.org   \n",
       "4     15100.0     Riley  Thompson  riley.thompson0.0@mail.test   \n",
       "\n",
       "             Phone  Age  YearsActive  NumChildren VIP  EstimatedAnnualSpend  \n",
       "0  +6-642-419-1833   56           11            2  No               5352.29  \n",
       "1  +5-208-357-5102   20            2            1  No               1554.88  \n",
       "2  +1-877-772-1298   34            7            2  No               3396.24  \n",
       "3  +5-854-311-7228   56            5            4  No               1243.36  \n",
       "4  +2-818-901-1646   42            1            3  No                661.39  "
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the loading function with the file paths. Replace '...' with the path to 'customer_info.csv'\n",
    "%run load_customer_data.py\n",
    "# Here the correct arguments should be added\n",
    "customers = load_customer_data(\"customer_info.csv\")\n",
    "\n",
    "customers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfcea55",
   "metadata": {},
   "source": [
    "#### 14) Create the **`average_age`** function, which takes two Pandas DataFrames as input: the retail DataFrame and the customer DataFrame. The function should use the one created in exercise 7) to obtain the list of the top 5 customers, and then **return a float representing the average age of these top 5 customers (those who placed the most orders).**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b797fc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting average_age.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile average_age.py\n",
    "import pandas as pd\n",
    "from top_five_cust import top_five_cust\n",
    "\n",
    "\n",
    "def average_age(df, customers) -> float:\n",
    "    # Create a copy of the Dataframe so it does not modify the original reference\n",
    "    df = df.copy()\n",
    "    customers = customers.copy()\n",
    "    \n",
    "    list_top_five_customers = top_five_cust(df)\n",
    "    customers_top_five = customers[customers['CustomerID'].isin(list_top_five_customers)]\n",
    "    # check if there is indentical ids \n",
    "    age_average = customers_top_five['Age'].mean()\n",
    "    return age_average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d70298f",
   "metadata": {},
   "source": [
    "#### Call your `average_age` function on the now cleaned `df` and `customers` below to view the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "25e3bf1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run average_age.py\n",
    "# Here the correct arguments should be added\n",
    "average_age(df, customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919e2aeb",
   "metadata": {},
   "source": [
    "#### 15) Create the **`most_active`** function, which takes the customer DataFrame as input and **returns a list of strings containing the emails of the customers who have been active for the longest period of time (`YearsActive`).**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "ee1ec814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting most_active.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile most_active.py\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "def most_active(customers) -> List[str]:\n",
    "    customers = customers.copy()\n",
    "    most_active_time = customers['YearsActive'].max()\n",
    "    customers_most_active = customers[customers['YearsActive'] == most_active_time]\n",
    "    # Improve this to return unique emails only \n",
    "    return list(customers_most_active['Email'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f1338e",
   "metadata": {},
   "source": [
    "#### Call your `most_active` function on the `customers` DataFrame below to view the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "9519d5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reese.taylor9.0@example.com',\n",
       " 'elliot.martin1.0@no-reply.io',\n",
       " 'parker.harris1.0@example.com',\n",
       " 'avery.king1.0@demo.org',\n",
       " 'cameron.martin7.0@demo.org',\n",
       " 'hayden.clark5.0@mail.test',\n",
       " 'reese.taylor5.0@sample.net',\n",
       " 'blake.clark8.0@sample.net',\n",
       " 'jamie.lee7.0@mail.test',\n",
       " 'alex.walker5.0@demo.org',\n",
       " 'elliot.young5.0@mail.test',\n",
       " 'jordan.thomas6.0@no-reply.io',\n",
       " 'blake.king1.0@no-reply.io',\n",
       " 'alex.thompson0.0@example.com',\n",
       " 'sam.white0.0@example.com',\n",
       " 'blake.lee5.0@example.com',\n",
       " 'cameron.jackson1.0@sample.net',\n",
       " 'elliot.clark8.0@mail.test',\n",
       " 'rowan.young3.0@no-reply.io',\n",
       " 'blake.jackson2.0@sample.net',\n",
       " 'casey.lee8.0@example.com',\n",
       " 'rowan.thomas2.0@demo.org',\n",
       " 'rowan.allen6.0@example.com',\n",
       " 'jordan.white9.0@sample.net',\n",
       " 'jamie.king8.0@demo.org',\n",
       " 'alex.lee4.0@sample.net',\n",
       " 'logan.anderson8.0@mail.test',\n",
       " 'avery.walker1.0@example.com',\n",
       " 'logan.young9.0@demo.org',\n",
       " 'logan.thomas4.0@example.com',\n",
       " 'jamie.garcia4.0@no-reply.io',\n",
       " 'reese.clark5.0@sample.net',\n",
       " 'elliot.lee4.0@mail.test',\n",
       " 'avery.young0.0@demo.org',\n",
       " 'elliot.king1.0@sample.net',\n",
       " 'morgan.taylor2.0@sample.net',\n",
       " 'morgan.harris1.0@demo.org',\n",
       " 'taylor.king3.0@no-reply.io',\n",
       " 'reese.anderson0.0@no-reply.io',\n",
       " 'jordan.walker9.0@sample.net',\n",
       " 'cameron.walker6.0@mail.test',\n",
       " 'blake.allen2.0@demo.org',\n",
       " 'morgan.thompson8.0@mail.test',\n",
       " 'quinn.lee2.0@mail.test',\n",
       " 'casey.johnson6.0@no-reply.io',\n",
       " 'parker.harris5.0@no-reply.io',\n",
       " 'quinn.smith2.0@sample.net',\n",
       " 'riley.allen2.0@example.com',\n",
       " 'jamie.thomas2.0@mail.test',\n",
       " 'jordan.harris8.0@example.com',\n",
       " 'taylor.martin1.0@example.com',\n",
       " 'logan.garcia5.0@example.com',\n",
       " 'quinn.garcia1.0@mail.test',\n",
       " 'hayden.young6.0@example.com',\n",
       " 'hayden.clark0.0@demo.org',\n",
       " 'casey.smith8.0@demo.org',\n",
       " 'blake.thompson4.0@no-reply.io',\n",
       " 'jamie.smith7.0@example.com',\n",
       " 'rowan.thompson9.0@example.com',\n",
       " 'alex.lee7.0@demo.org',\n",
       " 'parker.lee0.0@sample.net',\n",
       " 'parker.jackson6.0@demo.org',\n",
       " 'drew.king9.0@mail.test',\n",
       " 'avery.taylor5.0@mail.test',\n",
       " 'sam.young6.0@example.com',\n",
       " 'cameron.allen2.0@demo.org',\n",
       " 'logan.white2.0@example.com',\n",
       " 'elliot.young8.0@no-reply.io',\n",
       " 'rowan.king0.0@demo.org',\n",
       " 'taylor.white3.0@mail.test',\n",
       " 'hayden.king2.0@mail.test',\n",
       " 'morgan.thompson0.0@example.com',\n",
       " 'blake.lewis2.0@example.com',\n",
       " 'casey.martin5.0@demo.org',\n",
       " 'elliot.lewis1.0@demo.org',\n",
       " 'jordan.walker1.0@mail.test',\n",
       " 'drew.taylor7.0@example.com',\n",
       " 'sam.taylor0.0@sample.net',\n",
       " 'riley.white6.0@demo.org',\n",
       " 'sam.white6.0@mail.test',\n",
       " 'jamie.johnson6.0@example.com',\n",
       " 'logan.clark0.0@sample.net',\n",
       " 'cameron.smith2.0@mail.test',\n",
       " 'jamie.brown5.0@mail.test',\n",
       " 'casey.king4.0@sample.net',\n",
       " 'morgan.brown0.0@mail.test',\n",
       " 'morgan.thomas7.0@sample.net',\n",
       " 'cameron.clark5.0@demo.org',\n",
       " 'taylor.jackson6.0@demo.org',\n",
       " 'parker.taylor7.0@sample.net',\n",
       " 'elliot.taylor0.0@mail.test',\n",
       " 'cameron.clark7.0@sample.net',\n",
       " 'rowan.young2.0@no-reply.io',\n",
       " 'cameron.taylor3.0@example.com',\n",
       " 'chris.smith8.0@demo.org',\n",
       " 'chris.clark9.0@no-reply.io',\n",
       " 'drew.clark5.0@demo.org',\n",
       " 'casey.allen3.0@sample.net',\n",
       " 'elliot.allen5.0@example.com',\n",
       " 'riley.taylor1.0@example.com',\n",
       " 'blake.white0.0@mail.test',\n",
       " 'taylor.smith9.0@example.com',\n",
       " 'riley.king5.0@sample.net',\n",
       " 'jamie.thompson6.0@mail.test',\n",
       " 'chris.clark0.0@no-reply.io',\n",
       " 'reese.king4.0@example.com',\n",
       " 'jamie.brown6.0@no-reply.io',\n",
       " 'elliot.walker3.0@demo.org',\n",
       " 'logan.brown9.0@example.com',\n",
       " 'parker.king5.0@no-reply.io',\n",
       " 'taylor.thomas2.0@mail.test',\n",
       " 'avery.clark1.0@no-reply.io',\n",
       " 'drew.martin3.0@demo.org',\n",
       " 'alex.anderson6.0@example.com',\n",
       " 'cameron.brown9.0@no-reply.io',\n",
       " 'casey.allen6.0@no-reply.io',\n",
       " 'taylor.smith2.0@mail.test',\n",
       " 'riley.white3.0@sample.net',\n",
       " 'morgan.allen6.0@sample.net',\n",
       " 'sam.lee3.0@example.com',\n",
       " 'logan.allen9.0@example.com',\n",
       " 'morgan.thomas0.0@no-reply.io',\n",
       " 'blake.king6.0@demo.org',\n",
       " 'sam.thomas7.0@example.com',\n",
       " 'jordan.lewis9.0@no-reply.io',\n",
       " 'logan.brown6.0@demo.org',\n",
       " 'hayden.brown1.0@demo.org',\n",
       " 'rowan.walker9.0@demo.org',\n",
       " 'sam.walker8.0@example.com',\n",
       " 'parker.garcia6.0@example.com',\n",
       " 'blake.garcia7.0@no-reply.io',\n",
       " 'drew.thomas2.0@no-reply.io',\n",
       " 'reese.taylor5.0@demo.org',\n",
       " 'parker.king7.0@sample.net',\n",
       " 'reese.lewis1.0@demo.org',\n",
       " 'morgan.johnson4.0@no-reply.io',\n",
       " 'parker.young8.0@example.com',\n",
       " 'blake.taylor4.0@mail.test',\n",
       " 'morgan.lewis2.0@example.com',\n",
       " 'avery.taylor8.0@demo.org',\n",
       " 'hayden.brown5.0@sample.net',\n",
       " 'blake.johnson8.0@mail.test',\n",
       " 'cameron.walker0.0@demo.org',\n",
       " 'alex.thompson6.0@no-reply.io',\n",
       " 'rowan.white5.0@example.com',\n",
       " 'parker.young2.0@mail.test',\n",
       " 'alex.king5.0@example.com',\n",
       " 'sam.johnson5.0@example.com',\n",
       " 'casey.walker7.0@demo.org',\n",
       " 'blake.johnson4.0@sample.net',\n",
       " 'alex.thomas6.0@example.com',\n",
       " 'jamie.taylor9.0@sample.net',\n",
       " 'drew.clark5.0@no-reply.io',\n",
       " 'parker.jackson3.0@demo.org',\n",
       " 'reese.king5.0@mail.test',\n",
       " 'elliot.thomas5.0@example.com',\n",
       " 'drew.young3.0@example.com',\n",
       " 'riley.harris9.0@example.com',\n",
       " 'sam.thomas5.0@sample.net',\n",
       " 'cameron.thomas6.0@no-reply.io',\n",
       " 'casey.hall1.0@demo.org',\n",
       " 'casey.anderson8.0@mail.test',\n",
       " 'elliot.harris9.0@mail.test',\n",
       " 'reese.hall6.0@demo.org',\n",
       " 'quinn.lee7.0@demo.org',\n",
       " 'taylor.walker0.0@sample.net',\n",
       " 'jordan.clark2.0@demo.org',\n",
       " 'cameron.white4.0@no-reply.io',\n",
       " 'rowan.lewis4.0@demo.org',\n",
       " 'avery.clark6.0@demo.org',\n",
       " 'blake.martin8.0@example.com',\n",
       " 'parker.walker9.0@mail.test',\n",
       " 'blake.jackson5.0@demo.org',\n",
       " 'parker.young1.0@no-reply.io',\n",
       " 'blake.jackson1.0@no-reply.io',\n",
       " 'sam.martin6.0@demo.org',\n",
       " 'quinn.allen2.0@demo.org',\n",
       " 'alex.thomas6.0@no-reply.io',\n",
       " 'jordan.taylor0.0@demo.org',\n",
       " 'hayden.hall9.0@no-reply.io',\n",
       " 'reese.lee8.0@demo.org',\n",
       " 'taylor.thompson5.0@example.com',\n",
       " 'riley.garcia3.0@sample.net',\n",
       " 'taylor.garcia3.0@no-reply.io',\n",
       " 'parker.martin8.0@example.com',\n",
       " 'elliot.jackson9.0@demo.org',\n",
       " 'morgan.clark2.0@sample.net',\n",
       " 'jamie.anderson7.0@no-reply.io',\n",
       " 'elliot.thompson6.0@example.com',\n",
       " 'blake.anderson1.0@example.com',\n",
       " 'chris.anderson9.0@example.com',\n",
       " 'cameron.hall9.0@example.com',\n",
       " 'chris.thompson1.0@no-reply.io',\n",
       " 'drew.young9.0@demo.org',\n",
       " 'alex.walker5.0@sample.net',\n",
       " 'reese.anderson3.0@no-reply.io',\n",
       " 'morgan.lewis5.0@no-reply.io',\n",
       " 'reese.allen9.0@sample.net',\n",
       " 'jordan.thomas8.0@mail.test',\n",
       " 'avery.taylor8.0@mail.test',\n",
       " 'cameron.thomas7.0@mail.test',\n",
       " 'taylor.walker4.0@mail.test',\n",
       " 'logan.walker0.0@demo.org',\n",
       " 'chris.brown6.0@no-reply.io',\n",
       " 'blake.taylor0.0@no-reply.io',\n",
       " 'jamie.johnson9.0@mail.test',\n",
       " 'avery.martin6.0@example.com',\n",
       " 'alex.taylor9.0@sample.net',\n",
       " 'riley.white2.0@demo.org',\n",
       " 'jamie.anderson2.0@example.com',\n",
       " 'parker.brown9.0@demo.org',\n",
       " 'taylor.lewis4.0@demo.org',\n",
       " 'casey.martin4.0@demo.org',\n",
       " 'alex.smith2.0@no-reply.io',\n",
       " 'reese.thompson8.0@sample.net',\n",
       " 'reese.lewis9.0@demo.org',\n",
       " 'morgan.lewis5.0@demo.org',\n",
       " 'parker.martin2.0@mail.test',\n",
       " 'morgan.young0.0@sample.net',\n",
       " 'hayden.harris4.0@mail.test',\n",
       " 'quinn.young7.0@example.com',\n",
       " 'rowan.thompson1.0@demo.org',\n",
       " 'avery.thompson0.0@example.com',\n",
       " 'alex.harris6.0@example.com',\n",
       " 'jordan.walker8.0@example.com',\n",
       " 'drew.white7.0@example.com',\n",
       " 'reese.lewis0.0@example.com',\n",
       " 'parker.harris3.0@example.com',\n",
       " 'elliot.anderson2.0@no-reply.io',\n",
       " 'casey.brown6.0@demo.org',\n",
       " 'avery.white8.0@example.com',\n",
       " 'jamie.johnson7.0@demo.org',\n",
       " 'jamie.brown1.0@no-reply.io',\n",
       " 'alex.garcia9.0@no-reply.io',\n",
       " 'avery.lewis4.0@example.com',\n",
       " 'rowan.anderson1.0@sample.net',\n",
       " 'rowan.harris4.0@sample.net',\n",
       " 'avery.thompson8.0@mail.test',\n",
       " 'blake.thomas0.0@sample.net',\n",
       " 'drew.martin6.0@no-reply.io',\n",
       " 'cameron.brown3.0@mail.test',\n",
       " 'rowan.anderson2.0@no-reply.io',\n",
       " 'chris.martin9.0@mail.test',\n",
       " 'casey.jackson6.0@sample.net',\n",
       " 'morgan.jackson7.0@mail.test',\n",
       " 'chris.clark4.0@mail.test',\n",
       " 'chris.thompson5.0@example.com',\n",
       " 'drew.garcia3.0@demo.org',\n",
       " 'rowan.garcia1.0@mail.test',\n",
       " 'alex.thompson5.0@example.com',\n",
       " 'hayden.allen2.0@sample.net',\n",
       " 'rowan.walker5.0@mail.test',\n",
       " 'jamie.thompson6.0@no-reply.io',\n",
       " 'hayden.lewis0.0@demo.org',\n",
       " 'chris.allen1.0@demo.org',\n",
       " 'parker.johnson4.0@demo.org',\n",
       " 'blake.lee4.0@example.com',\n",
       " 'cameron.taylor1.0@no-reply.io',\n",
       " 'rowan.lewis7.0@example.com',\n",
       " 'sam.anderson5.0@example.com',\n",
       " 'jordan.young1.0@sample.net',\n",
       " 'jordan.young1.0@no-reply.io',\n",
       " 'quinn.lee7.0@no-reply.io',\n",
       " 'rowan.thompson9.0@no-reply.io',\n",
       " 'chris.hall5.0@mail.test',\n",
       " 'cameron.thompson0.0@demo.org',\n",
       " 'cameron.walker0.0@mail.test',\n",
       " 'avery.young7.0@demo.org',\n",
       " 'hayden.clark4.0@demo.org',\n",
       " 'jamie.young8.0@demo.org',\n",
       " 'drew.taylor5.0@mail.test',\n",
       " 'parker.harris0.0@example.com',\n",
       " 'casey.clark9.0@example.com',\n",
       " 'taylor.young7.0@mail.test',\n",
       " 'logan.white4.0@demo.org',\n",
       " 'parker.young9.0@demo.org',\n",
       " 'sam.thomas3.0@demo.org',\n",
       " 'taylor.lewis9.0@example.com',\n",
       " 'casey.smith4.0@no-reply.io',\n",
       " 'reese.brown4.0@demo.org',\n",
       " 'rowan.king0.0@no-reply.io',\n",
       " 'taylor.clark9.0@example.com',\n",
       " 'rowan.lewis9.0@sample.net',\n",
       " 'alex.young0.0@mail.test',\n",
       " 'rowan.allen3.0@sample.net',\n",
       " 'rowan.garcia2.0@example.com',\n",
       " 'avery.taylor6.0@sample.net',\n",
       " 'jordan.lewis0.0@mail.test',\n",
       " 'rowan.thomas5.0@mail.test',\n",
       " 'elliot.thomas5.0@sample.net',\n",
       " 'jordan.lee7.0@sample.net',\n",
       " 'avery.allen1.0@sample.net',\n",
       " 'parker.thompson6.0@no-reply.io',\n",
       " 'quinn.anderson4.0@sample.net',\n",
       " 'hayden.taylor9.0@sample.net',\n",
       " 'riley.anderson2.0@sample.net',\n",
       " 'elliot.clark1.0@example.com',\n",
       " 'reese.king9.0@sample.net',\n",
       " 'quinn.smith4.0@example.com',\n",
       " 'logan.johnson7.0@demo.org',\n",
       " 'cameron.thomas1.0@no-reply.io',\n",
       " 'elliot.young8.0@demo.org',\n",
       " 'quinn.lee8.0@example.com',\n",
       " 'parker.martin5.0@mail.test',\n",
       " 'cameron.hall5.0@example.com',\n",
       " 'drew.taylor2.0@example.com',\n",
       " 'morgan.king1.0@example.com',\n",
       " 'alex.harris8.0@example.com',\n",
       " 'cameron.thomas2.0@demo.org',\n",
       " 'logan.clark4.0@mail.test',\n",
       " 'morgan.lee6.0@example.com',\n",
       " 'jordan.lewis4.0@sample.net',\n",
       " 'jordan.white4.0@no-reply.io',\n",
       " 'logan.martin6.0@sample.net',\n",
       " 'reese.white5.0@demo.org',\n",
       " 'quinn.white9.0@sample.net',\n",
       " 'rowan.anderson3.0@mail.test',\n",
       " 'avery.hall3.0@no-reply.io',\n",
       " 'jordan.lee9.0@mail.test',\n",
       " 'avery.young0.0@example.com',\n",
       " 'hayden.anderson4.0@mail.test',\n",
       " 'hayden.martin7.0@mail.test',\n",
       " 'blake.thompson5.0@sample.net',\n",
       " 'reese.lee0.0@sample.net',\n",
       " 'casey.harris9.0@demo.org',\n",
       " 'avery.young6.0@sample.net',\n",
       " 'jordan.lewis0.0@demo.org',\n",
       " 'casey.harris3.0@no-reply.io',\n",
       " 'elliot.walker9.0@mail.test',\n",
       " 'chris.hall3.0@sample.net',\n",
       " 'hayden.hall3.0@example.com',\n",
       " 'logan.thompson1.0@example.com',\n",
       " 'alex.walker3.0@mail.test',\n",
       " 'chris.thomas1.0@demo.org',\n",
       " 'jamie.thompson7.0@mail.test',\n",
       " 'rowan.brown7.0@sample.net',\n",
       " 'alex.smith7.0@example.com',\n",
       " 'parker.lee7.0@no-reply.io',\n",
       " 'quinn.smith6.0@mail.test',\n",
       " 'jamie.young5.0@no-reply.io',\n",
       " 'logan.king8.0@example.com',\n",
       " 'blake.jackson0.0@sample.net',\n",
       " 'rowan.thomas1.0@sample.net',\n",
       " 'reese.brown2.0@mail.test',\n",
       " 'cameron.lee4.0@demo.org',\n",
       " 'rowan.thomas7.0@no-reply.io',\n",
       " 'drew.thompson9.0@demo.org',\n",
       " 'jamie.brown3.0@mail.test',\n",
       " 'parker.harris4.0@mail.test',\n",
       " 'alex.clark2.0@no-reply.io',\n",
       " 'chris.young2.0@no-reply.io',\n",
       " 'elliot.white4.0@mail.test',\n",
       " 'drew.young7.0@demo.org',\n",
       " 'taylor.walker5.0@no-reply.io',\n",
       " 'elliot.clark3.0@mail.test',\n",
       " 'quinn.johnson0.0@no-reply.io',\n",
       " 'quinn.harris8.0@no-reply.io',\n",
       " 'rowan.smith3.0@example.com',\n",
       " 'morgan.allen8.0@mail.test',\n",
       " 'riley.taylor7.0@mail.test',\n",
       " 'taylor.king2.0@example.com',\n",
       " 'quinn.king8.0@sample.net',\n",
       " 'blake.taylor3.0@mail.test',\n",
       " 'sam.thomas4.0@mail.test',\n",
       " 'quinn.hall7.0@example.com',\n",
       " 'hayden.garcia7.0@sample.net',\n",
       " 'logan.anderson1.0@example.com',\n",
       " 'reese.harris4.0@no-reply.io',\n",
       " 'morgan.martin3.0@example.com',\n",
       " 'cameron.lewis0.0@demo.org',\n",
       " 'hayden.johnson5.0@demo.org',\n",
       " 'blake.thomas0.0@mail.test',\n",
       " 'sam.allen0.0@no-reply.io',\n",
       " 'rowan.clark0.0@example.com',\n",
       " 'jamie.anderson3.0@demo.org',\n",
       " 'jamie.hall2.0@no-reply.io',\n",
       " 'rowan.thomas2.0@mail.test',\n",
       " 'elliot.white2.0@sample.net',\n",
       " 'blake.thomas2.0@sample.net',\n",
       " 'quinn.allen9.0@mail.test',\n",
       " 'morgan.johnson6.0@demo.org',\n",
       " 'riley.young2.0@example.com',\n",
       " 'logan.brown5.0@example.com',\n",
       " 'jordan.walker7.0@no-reply.io',\n",
       " 'blake.garcia4.0@mail.test',\n",
       " 'taylor.white6.0@example.com',\n",
       " 'sam.jackson5.0@no-reply.io',\n",
       " 'rowan.jackson3.0@demo.org',\n",
       " 'cameron.lewis4.0@mail.test',\n",
       " 'blake.johnson6.0@demo.org',\n",
       " 'jordan.hall0.0@example.com',\n",
       " 'casey.brown1.0@sample.net',\n",
       " 'avery.thomas0.0@no-reply.io',\n",
       " 'cameron.harris7.0@mail.test',\n",
       " 'blake.harris9.0@sample.net',\n",
       " 'sam.harris3.0@example.com',\n",
       " 'cameron.lee7.0@no-reply.io']"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run most_active.py\n",
    "# Here the correct arguments should be added\n",
    "# INVESTIGAR \n",
    "most_active(customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2739326b",
   "metadata": {},
   "source": [
    "#### 16) Create the **`parenthood_marketing`** function, which takes two Pandas DataFrames as input: the retail DataFrame and the customer DataFrame. The function should **return a list of 5 strings representing the countries with the highest average number of children among their customers.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "e08de44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting parenthood_marketing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile parenthood_marketing.py\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "def parenthood_marketing(df, customers) -> List[str]:\n",
    "    df = df.copy()\n",
    "    customers = customers.copy()\n",
    "    customers_country = df.merge(customers, on='CustomerID')\n",
    "    top_five_countries_with_most_children = customers_country.groupby('Country')['NumChildren'].mean().sort_values(ascending=False).head(5)\n",
    "    return top_five_countries_with_most_children.index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb52248",
   "metadata": {},
   "source": [
    "#### Call your `parenthood_marketing` function on the now cleaned `df` and `customers` below to view the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "daec1caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Italy', 'Denmark', 'Sweden', 'Lithuania', 'Finland']"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run parenthood_marketing.py\n",
    "# Here the correct arguments should be added\n",
    "parenthood_marketing(df, customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a07393",
   "metadata": {},
   "source": [
    "#### 17) Create the **`babuska_clients`** function, which takes two Pandas DataFrames as input: the retail DataFrame and the customer DataFrame. The function should **return a float representing the average age of the customers who purchased the** **`\"HAND WARMER BABUSHKA DESIGN\"`** **item.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "23afdfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting babuska_clients.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile babuska_clients.py\n",
    "import pandas as pd\n",
    "\n",
    "def babuska_clients(df, customers) -> float:\n",
    "    df = df.copy()\n",
    "    customers = customers.copy()\n",
    "    #merge dataframes\n",
    "    merged_df = df.merge(customers, on='CustomerID')\n",
    "    print(merged_df.columns)\n",
    "    merged_babushka_df = merged_df[merged_df['Description'] == \"HAND WARMER BABUSHKA DESIGN\"]\n",
    "    return float(merged_babushka_df['Age'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bb3126",
   "metadata": {},
   "source": [
    "#### Call your `babuska_clients` function on the now cleaned `df` and `customers` below to view the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "4324ab02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate',\n",
      "       'UnitPrice', 'CustomerID', 'Country', 'amount_spent', 'FirstName',\n",
      "       'LastName', 'Email', 'Phone', 'Age', 'YearsActive', 'NumChildren',\n",
      "       'VIP', 'EstimatedAnnualSpend'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46.67605633802817"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run babuska_clients.py\n",
    "# Here the correct arguments should be added\n",
    "babuska_clients(df, customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27868003",
   "metadata": {},
   "source": [
    "# Part III"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078bfa26",
   "metadata": {},
   "source": [
    "#### 18) Create the **`read_sport_dfs(teams_filepath: str, managers_filepath: str)`** function which loads the **`managers.csv`** and the **`teams.csv`** file into two Pandas DataFrames and returns them. Call this function and save the results into DataFrames named **`teams`** and **`managers`** respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "4685d2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting read_sport_dfs.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile read_sport_dfs.py\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "\n",
    "def read_sport_dfs(teams_filepath: str, managers_filepath: str) -> Tuple[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Loads sports datasets into pandas DataFrames.\n",
    "    Handles missing file paths and encoding issues gracefully.\n",
    "    \"\"\"\n",
    "    encoding = ['utf-8', 'latin1']\n",
    "    try:\n",
    "        # The default is utf-8 (we kept this to show that we are handling encoding exceptions)\n",
    "        # It will get an error, the file is not utf-8 encoded\n",
    "        teams_df = pd.read_csv(teams_filepath, sep=',', encoding=encoding[0])\n",
    "        managers_df = pd.read_csv(managers_filepath, sep=',', encoding=encoding[0])\n",
    "        return (teams_df, managers_df)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {filepath}\")\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Encoding error while reading the file: {filepath}\")\n",
    "        print(f\"Used {encoding[0]} encoding, will try to read the file again with {encoding[1]} encoding.\")\n",
    "        try : \n",
    "            teams_df = pd.read_csv(teams_filepath, sep=',', encoding=encoding[1])\n",
    "            managers_df = pd.read_csv(managers_filepath, sep=',', encoding=encoding[1])\n",
    "            return (teams_df, managers_df)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")  \n",
    "    return (teams_df, managers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "0cddd857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       yearID lgID teamID franchID divID  Rank   G  Ghome   W   L  ...  DP  \\\n",
      "0  1871-12-21  NaN    BS1      BNA   NaN     3  31    NaN  20  10  ... NaN   \n",
      "1  1871-09-07  NaN    CH1      CNA   NaN     2  28    NaN  19   9  ... NaN   \n",
      "2  1871-06-12  NaN    CL1      CFC   NaN     8  29    NaN  10  19  ... NaN   \n",
      "3  1871-02-13  NaN    FW1      KEK   NaN     7  19    NaN   7  12  ... NaN   \n",
      "4  1871-08-06  NaN    NY2      NNA   NaN     5  33    NaN  16  17  ... NaN   \n",
      "\n",
      "     FP                     name                          park  attendance  \\\n",
      "0  0.83     Boston Red Stockings           South End Grounds I         NaN   \n",
      "1  0.82  Chicago White Stockings       Union Base-Ball Grounds         NaN   \n",
      "2  0.81   Cleveland Forest Citys  National Association Grounds         NaN   \n",
      "3  0.80     Fort Wayne Kekiongas                Hamilton Field         NaN   \n",
      "4  0.83         New York Mutuals      Union Grounds (Brooklyn)         NaN   \n",
      "\n",
      "   BPF  PPF  teamIDBR  teamIDlahman45  teamIDretro  \n",
      "0  103   98       BOS             BS1          BS1  \n",
      "1  104  102       CHI             CH1          CH1  \n",
      "2   96  100       CLE             CL1          CL1  \n",
      "3  101  107       KEK             FW1          FW1  \n",
      "4   90   88       NYU             NY2          NY2  \n",
      "\n",
      "[5 rows x 48 columns]\n",
      "         managerID  yearID teamID lgID  inseason   G   W   L  rank plyrMgr\n",
      "0    wr ighha0 1m     1871    BS1  NaN         1  31  20  10     3       Y\n",
      "1      woodji0 1m     1871    CH1  NaN         1  28  19   9     2       Y\n",
      "2  p ab o r c h01m    1871    CL1  NaN         1  29  10  19     8       Y\n",
      "3       lennobi01m    1871    FW1  NaN         1  14   5   9     8       Y\n",
      "4   de an e ha01 m    1871    FW1  NaN         2   5   2   3     8       Y\n"
     ]
    }
   ],
   "source": [
    "# Use the loading function with the file paths. Replace '...' with the correct paths. They should reside in your current working directory.\n",
    "%run read_sport_dfs.py\n",
    "# Here the correct arguments should be added\n",
    "teams, managers = read_sport_dfs('Teams.csv', 'Managers.csv')\n",
    "print(teams.head())\n",
    "print(managers.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066e66d3",
   "metadata": {},
   "source": [
    "#### 19) Create the **`go_sports`** function, which takes two Pandas DataFrames as input: the teams DataFrame and the manager DataFrame. This function **returns a DataFrame containing only the team name, its managerID, the year (yearID) in the ```yyyy``` format, the number of wins (`W`) per team and team number of losses (`L`) per team.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "cf105054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting go_sports.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile go_sports.py\n",
    "import pandas as pd\n",
    "\n",
    "def go_sports(teams: pd.DataFrame, managers: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Create a copy of the Dataframes so it does not modify the original references\n",
    "    teams=teams.copy()\n",
    "    managers=managers.copy()\n",
    "    \n",
    "    teams = teams[['teamID', 'name', 'yearID', 'W','L']]\n",
    "    managers = managers[['teamID', 'yearID', 'managerID']]\n",
    "    managers['managerID'] = managers['managerID'].str.replace(' ', '', regex=False)\n",
    "    teams['yearID'] = pd.to_datetime(teams['yearID'])\n",
    "    teams['yearID'] = teams['yearID'].dt.year.astype(str)\n",
    "    managers['yearID'] = managers['yearID'].astype(str)\n",
    "    \n",
    "    teams_managers = pd.merge(\n",
    "        teams,\n",
    "        managers,\n",
    "        how='left',\n",
    "        on=['teamID', 'yearID']\n",
    "    )\n",
    "    \n",
    "    return teams_managers[['teamID', 'yearID', 'name', 'managerID', 'W', 'L']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d916802f",
   "metadata": {},
   "source": [
    "#### Call your `go_sports` function with the `managers` and `teams` DataFrames below to view the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "7013f5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teamID</th>\n",
       "      <th>yearID</th>\n",
       "      <th>name</th>\n",
       "      <th>managerID</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BS1</td>\n",
       "      <td>1871</td>\n",
       "      <td>Boston Red Stockings</td>\n",
       "      <td>wrighha01m</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CH1</td>\n",
       "      <td>1871</td>\n",
       "      <td>Chicago White Stockings</td>\n",
       "      <td>woodji01m</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CL1</td>\n",
       "      <td>1871</td>\n",
       "      <td>Cleveland Forest Citys</td>\n",
       "      <td>paborch01m</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FW1</td>\n",
       "      <td>1871</td>\n",
       "      <td>Fort Wayne Kekiongas</td>\n",
       "      <td>lennobi01m</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FW1</td>\n",
       "      <td>1871</td>\n",
       "      <td>Fort Wayne Kekiongas</td>\n",
       "      <td>deaneha01m</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3269</th>\n",
       "      <td>ARI</td>\n",
       "      <td>2011</td>\n",
       "      <td>Arizona Diamondbacks</td>\n",
       "      <td>gibsoki01m</td>\n",
       "      <td>94</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3270</th>\n",
       "      <td>SFN</td>\n",
       "      <td>2011</td>\n",
       "      <td>San Francisco Giants</td>\n",
       "      <td>bochybr01m</td>\n",
       "      <td>86</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3271</th>\n",
       "      <td>LAN</td>\n",
       "      <td>2011</td>\n",
       "      <td>Los Angeles Dodgers</td>\n",
       "      <td>mattido01m</td>\n",
       "      <td>82</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3272</th>\n",
       "      <td>COL</td>\n",
       "      <td>2011</td>\n",
       "      <td>Colorado Rockies</td>\n",
       "      <td>tracyji01m</td>\n",
       "      <td>73</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273</th>\n",
       "      <td>SDN</td>\n",
       "      <td>2011</td>\n",
       "      <td>San Diego Padres</td>\n",
       "      <td>blackbu02m</td>\n",
       "      <td>71</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3274 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     teamID yearID                     name   managerID   W   L\n",
       "0       BS1   1871     Boston Red Stockings  wrighha01m  20  10\n",
       "1       CH1   1871  Chicago White Stockings   woodji01m  19   9\n",
       "2       CL1   1871   Cleveland Forest Citys  paborch01m  10  19\n",
       "3       FW1   1871     Fort Wayne Kekiongas  lennobi01m   7  12\n",
       "4       FW1   1871     Fort Wayne Kekiongas  deaneha01m   7  12\n",
       "...     ...    ...                      ...         ...  ..  ..\n",
       "3269    ARI   2011     Arizona Diamondbacks  gibsoki01m  94  68\n",
       "3270    SFN   2011     San Francisco Giants  bochybr01m  86  76\n",
       "3271    LAN   2011      Los Angeles Dodgers  mattido01m  82  79\n",
       "3272    COL   2011         Colorado Rockies  tracyji01m  73  89\n",
       "3273    SDN   2011         San Diego Padres  blackbu02m  71  91\n",
       "\n",
       "[3274 rows x 6 columns]"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run go_sports.py\n",
    "# Here the correct arguments should be added\n",
    "go_sports(teams , managers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead0d563",
   "metadata": {},
   "source": [
    "#### 20) Create the **`go_manager`** function, which takes two Pandas DataFrames as input: the teams DataFrame and the manager DataFrame. This function first calls the `go_sports` function with managers and teams input and then saves the result in a variable called sports. Then, this function **returns the ID (`managerID`) as a correct string of the manager who has most wins (`W`) over their careers.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed568e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting go_manager.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile go_manager.py\n",
    "import pandas as pd\n",
    "from go_sports import go_sports\n",
    "\n",
    "def go_manager(teams: pd.DataFrame, managers: pd.DataFrame) -> str:\n",
    "    \n",
    "   # Step 1: Build the sports DataFrame\n",
    "   sports = go_sports(teams, managers)\n",
    "\n",
    "   teams = teams.copy()\n",
    "   managers = managers.copy()\n",
    "\n",
    "   most_wins = sports.groupby('managerID')['W'].sum().sort_values(ascending=False)\n",
    "   print(most_wins)\n",
    "   max_most_wins = most_wins.max()\n",
    "   best_manager = most_wins[most_wins == max_most_wins].index[0]\n",
    "\n",
    "   print('The manager with the most wins is: ')\n",
    "\n",
    "   return best_manager\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968ce3bc",
   "metadata": {},
   "source": [
    "#### Call your `go_manager` function with the `managers` and `teams` DataFrames below to view the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "7c877f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "managerID\n",
      "mackco01m     3829\n",
      "mcgrajo01m    3119\n",
      "larusto01m    2851\n",
      "coxbo01m      2529\n",
      "torrejo01m    2429\n",
      "              ... \n",
      "allisdo01m       2\n",
      "thompam99m       2\n",
      "boydbi01m        2\n",
      "millejo01m       0\n",
      "smithbi01m       0\n",
      "Name: W, Length: 674, dtype: int64\n",
      "The manager with the most wins is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mackco01m'"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run go_manager.py\n",
    "# Here the correct arguments should be added\n",
    "go_manager(teams, managers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
